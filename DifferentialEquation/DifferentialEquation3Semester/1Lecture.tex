Лектор Виктория Юрьевна Барсукова

ДУ - дефференциальное уравнение.

OДУ - обыкновенное дефференциальное уравнение.

\begin{title}[\Large]
  Дифференциальное уравнение первого порядка. Основные понятия. Геометрический
  смысл уравнения первого порядка
\end{title}

\begin{define}[обыкновенного дифференциального уравнения]
  ОДУ называется уравнение содержащее неизвестную функцию одной переменной и ее
  производные или дифференциалы

  $F(x, y(x), y'(x), \ldots, y^{(m)} (x)) = 0$ или


  $F(x, y(x), dx, dy, d^2 x, d^2 y, \ldots d^n x, d^n y) = 0$

  $$
  y'(x) = \frac{dy}{dx}
  $$
\end{define}

\begin{define}[порядка уравнения]
  Порядком уравнения называется максимальный порядок производной или
  дифференциала входящего в уравнение.
\end{define}

\begin{define}[решения ДУ]
  Решение ДУ называется функция определенная на $<a,b>$ дифференциируема столько
  раз каков порядок уравнения и которая при подстановке в уравнение обращает его
  в тождество.
\end{define}

\begin{block}[ДУ 1 порядка]
  $F(x, y(x), y'(x)) = 0$ или $F(x, y(x), dy, dx) = 0$

  $y'(x) = f(x, y(x))$ - уравнение разрешенное относительно производной. Тоже
  что $\frac{dy(x)}{dx} = f(x, y(x))$

  $f(x, y)$ - заданая функция с двумя независимыми переменными. Будем считать
  что эта функция определена и непрерывна в некоторой односвязной области $D$.
\end{block}

\begin{define}[решения ДУ 1 порядка]
  $y = \varphi (x)$ определена на $<a,b>$ то $\varphi (x)$
  называется решением уравнения $y'(x) = f(x, y(x))$ если

  1) $\varphi (x)$ диференциируема на $<a,b>$

  2) $\forall x \in <a,b> ~~ (x, \varphi(x)) \in D$

  3) $\forall x \in <a,b> ~~ \frac{d\varphi (x)}{dx} = f(x, \varphi(x))$

  График решения называется интегральной кривой
\end{define}

\begin{define}[задачи Коши]
  Задачей Коши для уравнения $y'(x) = f(x, y(x))$ называется следущая задача
  найти такое решение уравнения которое при заданом $x$ принимает
  заданное значение $y_0$, тоесть удовлитворяет условию $y(x_0) = y_0$
  - условие Коши или начальное условие
  $$
  \left\{
  \begin{array}{l}
    y'(x) = f(x, y(x)) \\
    y(x_0) = y_0
  \end{array}
  \right.
  $$
\end{define}

\begin{define}[общего решния ДУ]
  Общим решением уравнения $y'(x) = f(x, y(x))$ называется функция $y = y(x,c)$
  такая что $\forall C$ функция является решением уравнения и любое
  решение уравнение входит в это семейство при некоторых $C$.

  Решение при конкретном $C$ называется частным решением.
\end{define}

\begin{define}[изоклина]
  $y' = f(x,y) ~~~ y'(x) = \tg \alpha ~~~ \tg \alpha = f(x,y) ~~~
  \tg \alpha = A ~ \Rightarrow ~ f(x,y) = A$

  $f(x, y) = A$ - изоклин
\end{define}

\begin{define}[интегральных типов уравнений]
  $$
  y'(x) = f(x, y(x))
  $$
  $$
  y'(x) = f(x) ~~~ y(x) = \int f(x)dx + C
  $$
  $$
  \left( \int_{x_0}^x f(t) dt \right)' = f(x) ~~~ \int f(x)dx = \int_{x_0}^x
  f(t)dt + C
  $$
  $$
  y(x) = \int_{x_0}^x f(t)dt + C ~ \text{- общее решение}
  $$
  $$
  y(x) = \int_{x_0}^x f(t)dt + y_0 ~ \text{- решение задачи Коши}
  $$
\end{define}

\begin{title}[\Large]
  Уравнения с разделяющимися переменными
\end{title}

\begin{define}[уравнения с разделяющимися переменными]
  Уравнения с разделяющимися переменными (УРП). Тоесть уравнения которые
  могут быть переведены к такому виду
  $$
  y'(x) = f(x) \cdot g(y(x))
  $$
  $$
  \frac{dy(x)}{dx} = f(x) \cdot g(y(x))
  $$
\end{define}

\begin{block}[Общий вид решения УРП]
  $$
  \frac{dy(x)}{g(y(x))} = \int f(x)dx ~~~ g(y(x)) \not= 0
  $$
  $$
  \int \frac{dy(x)}{g(y(x))} = \int f(x)dx
  $$
\end{block}

\begin{title}[\Large]
  Теорема существования и единственности решения задачи Коши для уравнения с
  разделяющимися переменными
\end{title}

\begin{theorem}[о $\exists !$ решения УРП]
  Пусть $f(x), g(u)$ определены и непрерывны на $x \in <a, b> ~ u \in <c, d>$
  $g(u) \not= 0 ~~~ \forall u \in <c, d>$ тогда
  $\forall x_0 \in <a, b> ~~~ \forall y_0 \in <c, d>$
  $$
  \left\{
  \begin{array}{l}
    y'(x) = f(x, y(x)) \\
    y(x_0) = y_0
  \end{array}
  \right.
  $$
  имеет единственное решение

  Замечание: $\exists m \in <c, d> ~ g(m) = 0$ тогда $y(x) \equiv m$
\end{theorem}

\begin{proof}
  Предположим что $\varphi(x)$ - решение уравнения $y'(x) = f(x, y(x))$
  удовлетворяющее $y(x_0) = y_0$ тоесть $\varphi(x_0) = y_0$
  $$
  \frac{d\varphi(x)}{dx} \equiv f(x)g(\varphi(x)) ~~~ x \in <a, b>
  $$
  $$
  \frac{d(\varphi(x))}{g(\varphi(x))} \equiv f(x)dx
  $$
  $$
  \int_{x_0}^x \frac{d(\varphi(t))}{g(\varphi(t))} = \int_{x_0}^x f(t)dt
  $$
  $$
  u = \varphi(t) ~~~ \int_{\varphi(x_0)}^{\varphi(x)} \frac{du}{g(u)} =
  \int_{x_0}^x f(t)dt
  $$
  $$
  \int_{y_0}^{\varphi(x)} \frac{du}{g(u)} = \int_{x_0}^x f(t)dt
  $$
  $$
  G(u) |_{y_0}^{\varphi(x)} = F(x) - F(x_0)
  $$
  $$
  G(\varphi(x)) = G(y_0) + F(x) - F(x_0)
  $$
  $g(u) \not= 0$ $g(u)$ - сохраняет знак $G'(u) = \frac{1}{g(u)}$ - сохраняет
  знак $G'(u) \not= 0$ $G(u)$ - строго монотонна и непрерывна $\Rightarrow$
  существает обратная ей функция
  $$
  \varphi(x) = G^{-1} \left( G(y_0) + \int_{x_0}^x f(t)dt \right)
  $$
  из едеинственности обратной функции $\Rightarrow$ единственность решения \\

  Докажем существование
  $$
  \varphi(x_0) = G^{-1}(G(y_0)) = y_0
  $$
  $$
  (G^{-1}(y))' = \frac{1}{G'(G^{-1}(y))}
  $$
  $$
  \varphi'(x) = \frac{1}{G' \left( G^{-1} \left( G(y_0)
  + \int_{x_0}^x f(t)dt \right) \right)}
  \left( G(y_0) + \int_{x_0}^x f(t)dt \right)' =
  $$
  $$
  = f(x) \cdot g \left( G^{-1} \left( G(y_0) +
  \int_{x_0}^x f(t)dt \right) \right) = f(x) \cdot g(\varphi(x))
  $$
  $\Rightarrow ~ \varphi(x)$ - решение задачи
\end{proof}

\begin{theorem}
  Если $\int_m \frac{du}{g(u)}$ - расходится, то через каждую точку области
  проходит единственное решение

  Если $\int_m \frac{du}{g(u)}$ - сходится, то в точка $y = m$ единтвсенность
  нарушена
\end{theorem}

\begin{title}[\Large]
  Уравнения приводящие к УРП
\end{title}

\begin{block}[Уравнения сводящиеся к линейной заменой]
  $$
  y'(x) = f(\alpha x + \beta y(x) + \gamma) ~~~ \alpha, \beta, \gamma \in R
  $$
  $$
  z(x) = \alpha x + \beta y(x) + \gamma ~ \Rightarrow z'(x) = \alpha +
  \beta y'(x) ~~~ \beta \not= 0
  $$
  $$
  \frac{z'(x) - \alpha}{\beta} = f(z(x))
  $$
  $$
  z'(x) = \beta f(z(x)) + \alpha ~~ \text{тоже что и} ~~
  z'(x) = 1 \cdot g(z(x))
  $$
\end{block}

\begin{block}[Однородные уравнения]
  $$
  y'(x) = \Phi \left( \frac{y(x)}{x} \right) ~ \text{замена} ~ z(x) =
  \frac{y(x)}{x}
  $$
  $$
  y(x) = z(x) \cdot x
  $$
  $$
  y'(x) = z'(x) x + z(x)
  $$
  $$
  x z'(x) + z(x) = \Phi(z(x))
  $$
  $$
  z'(x) = \frac{\Phi(z(x)) - z(x)}{x}
  $$
\end{block}

\begin{title}[\Large]
  Линейное уравнение 1-ого порядка
\end{title}

\begin{define}[линейного однородного и неоднородного уравнения]
  $y'(x) = a(x)y(x) + b(x)$ - линейное неоднородное уравнение

  $y'(x) = a(x)y(x)$ - линейное однородное уравнение
\end{define}

\begin{block}[Общее решение линейного однородного уравнения]
  $$
  y'(x) = a(x)y(x)
  $$
  $$
  \frac{dy(x)}{dx} = a(x)y(x)
  $$
  $$
  \int \frac{dy(x)}{y} = \int a(x)dx ~~~ y \not= 0
  $$
  $$
  \ln y(x) = \in a(x)dx
  $$
  $$
  |y(x)| = e^{\int_{x_0}^x a(t) dt + C}
  $$
  $$
  y(x) = C e^{\int_{x_0}^x a(t) dt}
  $$
\end{block}

\begin{block}[Метод вариации произвольной постоянной]
  $$
  y(x) = C(x) e^{\int_{x_0}^x a(t) dt}
  $$
  найдем $C(x)$ там чтобы $y(x)$ стал решением
  $$
  y'(x) = C'(x) \cdot e^{\int_{x_0}^x a(t) dt} +
  C(x) \cdot \left( e^{\int_{x_0}^x a(t) dt} \right)' =
  $$
  $$
  = C'(x) \cdot e^{\int_{x_0}^x a(t) dt} +
  C(x) \cdot e^{\int_{x_0}^x a(t) dt} a(x)
  $$
  $$
  C'(x) \cdot e^{\int_{x_0}^x a(t) dt} +
  C(x) \cdot e^{\int_{x_0}^x a(t) dt} a(x) =
  a(x) C(x) \cdot e^{\int_{x_0}^x a(t) dt} + b(x)
  $$
  $$
  C'(x) = \frac{b(x)}{e^{\int_{x_0}^x a(t) dt}} =
  b(x) e^{-\int_{x_0}^x a(t) dt}
  $$
  $$
  C(x) = \int_{x_0}^x b(s) e^{\int_{x_0}^s a(t) dt} ds + D
  $$
  $$
  y(x) = \left( \int_{x_0}^{\alpha} e^{-\int_{x_0}^t a(\tau) d\tau}
  b(t)dt + D \right) \cdot e^{\int_{x_0}^x a(\tau) d\tau} =
  $$
  $$
  = D e^{\int_{x_0}^x a(\tau) d\tau} + \int_{x_0}^x
  e^{\int_{x_0}^x a(\tau) d\tau - \int_{x_0}^x a(\tau) b\tau} d(t)dt
  $$
  $$
  y(x) = D e^{\int_{x_0}^x a(\tau) d\tau} + \int_{x_0}^x
  e^{\int_{t}^x a(\tau) d\tau} b(t)dt
  $$
  общее решение неоднородного уравнения
\end{block}

\begin{block}[Формула Коши]
  $$
  \left\{
  \begin{array}{l}
    y'(x) = a(x)y(x) + b(x) \\
    y(x_0) = y_0
  \end{array}
  \right. ~~~ \text{задача Коши}
  $$
  $$
  y(x) = y_0 e^{\int_{x_0}^x a(\tau) d\tau} + \int_{x_0}^x
  e^{\int_{t}^x a(\tau) d\tau} b(t)dt
  $$

  Введем обозначения

  $$
  K(x, t) = e^{\int_t^x a(\tau) d\tau}
  $$
  $$
  y(x) = y_0 K(x, x_0) + \int_{x_0}^x K(x, t) b(t) dt
  $$
  $K(x, t)$ - функция Коши
\end{block}

\begin{block}[Свойства]
  1) $K(x, x) = 1$

  2) при каждом фиксираванном $t \in <\alpha, \beta> ~ K(x, t)$ есть решение
  $y'(x) = a(x)y(x)$
\end{block}

\begin{theorem}
  Пусть $a(x), b(x)$ определена и непрерывна $\forall \in <\alpha, \beta>$
  тогда задача Коши $\forall x_0 \in <\alpha, \beta> ~~~ \forall y_0 \in R$
  $\exists !$ решение которое выражается
  $$
  y(x) = y_0 e^{\int_{x_0}^x a(\tau) d\tau} + \int_{x_0}^x
  e^{\int_{t}^x a(\tau) d\tau} b(t)dt
  $$
\end{theorem}

\begin{proof}
  Предположим что есть другое решение задачи Коши тогда
  $$
  \varphi(x) = u(x) e^{\int_{x_0}^x a(\tau)d\tau}
  $$
  проделов те же действия что и в методе вариаций получим что
  $\varphi(x) = y(x)$ $\Rightarrow$ единственность есть.

  Проверим что формула Коши действительно определяет решение задачи Коши
  $$
  y'(x) = y_0 e^{\int_{x_0}^x a(\tau) d\tau} a(x) + \left( \int_{x_0}^x
  e^{\int_{t}^x a(\tau) d\tau} b(t)dt \cdot
  e^{\int_{x_0}^x a(\tau)d\tau} \right)' =
  $$
  $$
  \left( \int_{\alpha(x)}^{\beta(x)} F(x, t) dt \right)' =
  F(x, \beta(x)) \beta'(x) - F(x, \alpha(x)) \alpha'(x) +
  \int_{\alpha(x)}^{\beta(x)} F_x(x, t)dt
  $$
  $$
  = y_0 e^{\int_{x_0} a(\tau)d\tau} a(x) + b(x) e^{-\int_{x_0}^x a(\tau) d\tau}
  e^{\int_{x_0}^x a(\tau) d\tau} +
  $$
  $$
  + \int_{x_0}^x b(t)
  e^{-\int_{x_0}^t a(\tau) d\tau} e^{\int_{x_0}^x a(\tau) d\tau} a(x) dt =
  $$
  $$
  a(x) \left( y_0 e^{\int_{x_0}^x a(\tau) d\tau} + \int_{x_0}^x b(t)
  e^{\int_t^x a(\tau) d\tau dt} \right) + b(x) =
  $$
  $$
  = a(x)y(x) + b(x)
  $$
\end{proof}

\begin{block}[Уравнение Бернули]
  $$
  y'(x) = a(x)y(x) + b(x)y^m(x) ~~~ m \not= 0 ~~~ m \not= 1
  $$
  $$
  \frac{y'(x)}{y^m(x)} = a(x) y^{1 - m}(x) + b(x)
  $$
  $$
  z(x) = y^{1 - m}(x)
  $$
  $$
  z'(x) = (1 - m) y^{-m}(x) y'(x) = \frac{(1-m)y'(x)}{y^m(x)} ~ \Rightarrow
  $$
  $$
  \frac{y'(x)}{y^m(x)} = \frac{z'(x)}{1 - m}
  $$
  $$
  z'(x) = (1 - m) a(x)z(x) + (1 - m)b(x) ~
  \text{- линейное уравнение}
  $$
\end{block}

\begin{title}[\Large]
  Уравнение в полных дифференциалах
\end{title}

Если частные производные 2-ого порядка существуют и непрерывны, то она равны
$$
\left( \frac{\partial^2 f}{\partial x \partial y},
\frac{\partial^2 f}{\partial y \partial x} \right)
$$

\begin{define}[уравнения в полных дифференциалах]
  Уравнение вида $P(x, y)dx + Q(x, y)dy = 0$ называется, уравнением в полных
  дифференциалах, если левая часть уравнения есть дифференциал некоторой
  функции тоесть выполнено условие
  $$
  \frac{\partial P(x, y)}{\partial y} = \frac{\partial Q(x, y)}{\partial x}
  $$
  $\Rightarrow ~ \exists F(x, y)$ чей дифференциал стоит слева
  $$
  \left\{
  \begin{array}{l}
    \frac{\partial F(x, y)}{\partial x} = P(x, y) \\
    \frac{\partial F(x, y)}{\partial y} = Q(x, y)
  \end{array}
  \right.
  $$
  $dF(x, y) = 0 ~ \Rightarrow ~ F(x, y) \equiv C$ 1-ый интеграл уравнения
\end{define}

\begin{block}[Решение уравнений в полых дифференциалах в общем виде]
  $$
  F(x, y) = \int_{x_0}^x P(t, y)dt + C(y)
  $$
  $$
  \frac{\partial F(x, y)}{\partial y} =
  \left( \int_{x_0}^x P(t, y)dt + C(y) \right)'_y =
  \int_{x_0}^x \frac{\partial P(t, y)}{\partial y} dt + C'(y) =
  $$
  $$
  = \int_{x_0}^x \frac{\partial Q(t, y)}{\partial t} dt + C'(y) =
  Q(t, y)|_{x_0}^x + C'(y) = Q(x, y) - Q(x_0, y) + C'(y) = Q(x, y)
  $$
  $$
  C'(x) = Q(x_0, y)
  $$
  $$
  C(y) = \int_{y_0}^y Q(x_0, s) ds + D
  $$
  $$
  F(x, y) = \int_{x_0}^x P(t, y) \int_{y_0}^y Q(x_0, s) ds + D
  $$
  $$
  \int_{x_0}^x P(t, y)dt + \int_{y_0}^y Q(x_0, s) ds = C ~ \text{- решение}
  $$
\end{block}

\begin{theorem}
  Пусть $P(x, y) ~ Q(x, y)$ непрерывны в некоторой односвязной области $G$
  $Q(x, y) \not= 0 ~~~ (x,y) \in G$ и существуют непрерывные частные
  производные, тогда $\forall (x_0, y_0) \in G_0$ задача Коши
  $\exists !$ решение
\end{theorem}

\begin{title}
  Система дифференциальных уравнений в нормальной форме
\end{title}

\begin{define}
  $$
  \left\{
  \begin{array}{l}
    x_1'(t) = f_1(t, x_1(t), x_2(t), \ldots, x_n(t)) \\
    x_2'(t) = f_2(t, x_1(t), x_2(t), \ldots, x_n(t)) \\
    \ldots ~~~ \ldots ~~~ \ldots ~~~ \ldots ~~~ \ldots ~~~ \ldots \\
    x_n'(t) = f_n(t, x_1(t), x_2(t), \ldots, x_n(t))
  \end{array}
  \right.
  $$
  $$
  x(t) =
  \left(
  \begin{array}{l}
    x_1(t) \\
    x_2(t) \\
    \ldots \\
    x_n(t)
  \end{array}
  \right) ~~~
  f(t) =
  \left(
  \begin{array}{l}
   f_1(t, x_1(t), x_2(t), \ldots, x_n(t)) \\
   f_2(t, x_1(t), x_2(t), \ldots, x_n(t)) \\
    \ldots ~~~ \ldots ~~~ \ldots ~~~ \ldots ~~~ \ldots \\
   f_n(t, x_1(t), x_2(t), \ldots, x_n(t))
  \end{array}
  \right)
  $$
  $x'(t) = f(t, x(t))$ $x(t)$ - неизвестный вектор функции
  $$
  <\alpha, \beta> \in R^n ~~~ x(t_0) = x_0 ~~~ t_0 \in <\alpha, \beta> ~~~
  x_0 \in R^n
  \left\{
  \begin{array}{l}
    x_1(t_0) = x_{0_1} \\
    x_2(t_0) = x_{0_2} \\
    \ldots ~~~ \ldots \\
    x_n(t_0) = x_{0_n}
  \end{array}
  \right.
  $$
\end{define}

\begin{block}[Решением системы ДУ называется]
  $\varphi(t): ~ <\varphi, \beta> \to R^n$ которая

  1) непрерывна дифференциируема на $<\alpha, \beta>$

  2) $\forall t \in <\alpha, \beta> ~~~ (t, \varphi(t)) \in D$

  3) $\frac{d\varphi(t)}{dt} \equiv f(t, \varphi(t)) ~~~
  t \in <\alpha, \beta>$
\end{block}

\begin{title}[\Large]
  Линейные системы дифференциальных уравнений (ЛСДУ)
\end{title}

$$
\left\{
\begin{array}{l}
  x'_1(t) = a_{11}(t)x_1(t) + a_{12}(t)x_2(t) + \ldots
  + a_{1n}x_n(t) + g_1(t) \\
  x'_2(t) = a_{21}(t)x_1(t) + a_{22}(t)x_2(t) + \ldots
  + a_{2n}x_n(t) + g_2(t) \\
  \ldots ~~~ \ldots ~~~ \ldots ~~~ \ldots ~~~ \ldots ~~~ \ldots ~~~
  \ldots ~~~ \ldots ~~~ \ldots ~~~ \ldots\\
  x'_n(t) = a_{n1}(t)x_1(t) + a_{n2}(t)x_2(t) + \ldots
  + a_{nn}x_n(t) + g_n(t) \\
\end{array}
\right.
$$

$$
x(t) =
\left(
\begin{array}{l}
  x_1(t) \\
  x_2(t) \\
  \ldots \\
  x_n(t)
\end{array}
\right) ~~~
A(t) =
\left(
\begin{array}{cccc}
  a_{11} & a_{12} & \ldots & a_{1n} \\
  a_{21} & a_{22} & \ldots & a_{2n} \\
  \ldots & \ldots & \ldots & \ldots \\
  a_{n1} & a_{n2} & \ldots & a_{nn}
\end{array}
\right) ~~~
g(t) =
\left(
\begin{array}{l}
  g_1(t) \\
  g_2(t) \\
  \ldots \\
  g_n(t) \\
\end{array}
\right)
$$

$x'(t) = A(t)x(t) + g(t)$ - неоднородная система

$x'(t) = A(t)x(t)$ - однородная система

\begin{title}[\Large]
  Теорема о существовании единственности для линейных систем. Рещение задачи
  Коши
\end{title}

\begin{theorem}
  Пусть $A(t) g(t)$ непрерывны на $<\alpha, \beta>$ тогда
  $\forall t_0 \in <\alpha, \beta> ~~~ \forall x_0 \in R^n$ задачи Коши
  $\exists !$ решение на $<\alpha, \beta>$
\end{theorem}

\begin{block}[Лемма]
  Задача Коши эквивалентна
  $$
  x(t) = x_0 + \int_{t_0}^t A(s)x(s)dx +
  \int_{t_0}^t g(s)ds
  $$
  тоесть любое решение задачи Коши явялется решением этого уравнения и наоборот
\end{block}

\begin{proof}
  Доказательство в одну сторону
  Пусть $\varphi$ - решение задачи Коши тогда
  $$
  \varphi'(t) = A(t)\varphi(t) + g(t)
  $$
  $$
  \int_{t_0}^t \varphi'(s)ds = \int_{t_0}^t A(s) \varphi(s)ds +
  \int_{t_0}^t g(s) ds
  $$
  $$
  \int_{t_0}^t \varphi'(s)ds = \varphi(s)|_{t_0}^t = \varphi(t) - x_0
  $$
  $$
  \varphi(t) = x_0 + \int_{t_0}^t A(s) \varphi(s) ds  + \int_{t_0}^t g(s)ds
  $$
  Доказательство в другую сторону

  Пусть $\varphi(t)$ - решение
  $$
  x(t) = x_0 + \int_{t_0}^t A(s)x(s)dx +
  \int_{t_0}^t g(s)ds
  $$
  тогда $\varphi(t)$ - непрерывная $\Rightarrow$ дифференцируема

  $\varphi'(t) = A(t)\varphi(t) + g(t)$

  $\varphi(t_0) = x_0$
\end{proof}

\begin{title}[\Large]
  Множество решений линейной системы
\end{title}

\begin{theorem}[прицапа суперпозии решений]
  $\varphi(t)$ решение $x'(t) = A(t)x(t) + g_1(t)$

  $\psi(t)$ решение $x'(t) = A(t)x(t) + g_2(t)$

  тогда $C\varphi(t) + B\psi(t)$ решение $x'(t) = A(t)x(t) + Cg_1(t) + Bg_2(t)$
  $C,B$ - числа
\end{theorem}

\begin{proof}
  $$
  C\varphi'(t) + B\varphi'(t) = A(t)(C\varphi(t) + B\psi(t)) + Cg_1(t) +
  Bg_2(t)
  $$
  $$
  C\varphi'(t) + B\varphi'(t) = C(A(t)\varphi(t) + g_1(t))+
  B(A(t)\psi(t) + g_2(t))
  $$
  $$
  \Rightarrow ~ A(t)\varphi(t) + g_1(t) = \varphi'(t) ~~~
  A(t)\psi(t) + g_2(t) = \psi'(t)
  $$
\end{proof}

\begin{block}[Следствие 1]
  Разность двух решений неоднородной системы $x'(t) = A(t)x(t) + g(t)$
  является решением неоднородной системы $x'(t) = A(t)x(t)$
\end{block}

\begin{proof}
  $x'(t) = A(t)x(t) + g(t) ~~ C = 1 ~~ B = 1$

  $\varphi(t) - \psi(t)$

  $g(t) - g(t) = 0$
\end{proof}

\begin{block}[Слeдствие 2]
  Если $\varphi_0(t)$ некоторое решение сисетмы $x'(t) = A(t)x(t) + g(t)$ то
  множество всех решений этой системы совпадает с множеством следующего вида
  $\{\varphi_0(t) + \varphi(t)\}$ где $\varphi(t)$ пробегает множество решений
  однородной системы
\end{block}

\begin{proof}
  $\varphi_0(t)$ решение $x'(t) = A(t)x(t) + g(t)$

  $\varphi(t)$ решение $x'(t) = A(t)x(t)$

  $\varphi_0(t) + \varphi(t)$ решение $x'(t) = A(t)x(t) + g(t)$

  Пусть $\varphi(t)$ решение $x'(t) = A(t)x(t) + g(t)$

  $\psi(t) - \varphi_0(t)$ решение $x'(t) = A(t)x(t)$

  $\Rightarrow ~ \varphi(t) = \varphi_0(t) - \varphi(t)$
\end{proof}

\begin{define}
  $$
  \varphi_1 (t) =
  \left(
  \begin{array}{c}
    \varphi_{11}(t) \\
    \cdots \\
    \varphi_{1n}(t) \\
  \end{array}
  \right),~~~
  \varphi_2 (t) =
  \left(
  \begin{array}{c}
    \varphi_{21}(t) \\
    \cdots \\
    \varphi_{2n}(t) \\
  \end{array}
  \right), \cdots,
  \varphi_k (t) =
  \left(
  \begin{array}{c}
    \varphi_{k1}(t) \\
    \cdots \\
    \varphi_{kn}(t) \\
  \end{array}
  \right) ~~~ t \in <\alpha, \beta>
  $$
  $\varphi, \cdots, \varphi_k(t)$ называется ЛЗ если $\exists C_1, C_2, \ldots,
  C_k(\sum_{j=1}^k cj^2 \not= 0)$ то комбинация $C_1\varphi_1(t) +
  C_2\varphi_2(t) + \ldots + C_k\varphi_k(t) = 0 ~ t \in <\alpha, \beta>$. В
  противном случае система функций ЛНЗ
\end{define}

\begin{theorem}
  Множество всех решений однородной системы $x'(t) = A(t)x(t)$ образует
  линейное пространство размерность которого совпадает с размерностью системы
\end{theorem}

\begin{proof}
  если $\varphi_1(t), \varphi_2(t)$ - решение $x'(t) = A(t)x(t) ~ \Rightarrow ~
  C_1\varphi_1(t) + C_2\varphi_2(t)$ решение $x'(t) = A(t)x(t)$

  $\varphi'_j(t) = A(t)\varphi_j(t)$

  $C_1 \varphi'_1(t) + C_2 \varphi'_2(t) = C_1(A(t) \varphi_1(t)) +
  C_2A^{(t)}\varphi_2(t) = A(t)(C_1\varphi_1(t) + C_2\varphi_2(t)) ~
  \Rightarrow ~ C_1 \varphi_1(t) + C_2 \varphi_2(t)$ решение
  $x'(t) = A(t)x(t)$\\

  Построим $n$ ЛНЗ решений $t \in <\alpha, \beta>$ возьмем $t_0 \in
  <\alpha, \beta>$
  $$
  e_1 =
  \left(
  \begin{array}{c}
    1 \\
    0 \\
    \cdots \\
    0
  \end{array}
  \right), ~~~
  e_2 =
  \left(
  \begin{array}{c}
    0 \\
    1 \\
    \cdots \\
    0
  \end{array}
  \right), \cdots,
  e_k =
  \left(
  \begin{array}{c}
    0 \\
    0 \\
    \cdots \\
    1
  \end{array}
  \right) ~~ \text{ЛНЗ}
  $$
  $$
  \left\{
  \begin{array}{c}
    x'(t) = A(t)x(t) \\
    x(t_0) = e_k
  \end{array}
  \right. ~~~ k = 1, 2, \ldots, n
  $$
  $\varphi_k(t)$ - единственое решение $\varphi_1(t), \ldots, \varphi_n(t) ~~~
  t \in <\alpha, \beta$

  покажем ЛНЗ $C_1 \varphi_1(t) + \ldots + C_n \varphi_n(t) \equiv 0 ~~~
  t = t_0$

  $C_1 \varphi_1(t_0) + C_2 \varphi_2(t_0) + \ldots + C_n \varphi_n(t_0)
  \equiv 0$
  $$
  C_1
  \left(
  \begin{array}{c}
    1 \\
    0 \\
    \cdots \\
    0
  \end{array}
  \right) +
  C_2
  \left(
  \begin{array}{c}
    0 \\
    1 \\
    \cdots \\
    0
  \end{array}
  \right) + \cdots +
  C_k
  \left(
  \begin{array}{c}
    0 \\
    0 \\
    \cdots \\
    1
  \end{array}
  \right) =
  \left(
  \begin{array}{c}
    0 \\
    0 \\
    \cdots \\
    0
  \end{array}
  \right)
  $$
  $$
  \left(
  \begin{array}{c}
    C_1 \\
    C_2 \\
    \cdots \\
    C_n
  \end{array}
  \right) =
  \left(
  \begin{array}{c}
    0 \\
    0 \\
    \cdots \\
    0
  \end{array}
  \right) ~ \Rightarrow ~ C_1 = C_2 = \ldots = C_n = 0 ~ \Rightarrow ~
  \varphi_1(t), \ldots, \varphi_n(t) ~~~ \text{- ЛНЗ}
  $$\\

  $\psi(t)$ произвольное решение
  $$
  \psi(t_0) =
  \left(
  \begin{array}{c}
    a_1 \\
    a_2 \\
    \cdots \\
    a_n
  \end{array}
  \right)
  $$
  $\varphi = a_1 \varphi_1(t) + \ldots + a_n \varphi_n(t)$

  $\psi(t) \equiv \varphi(t)$

  Заменим:
  $$
  \psi(t) =
  \left\{
  \begin{array}{c}
  x'(t) = A(t)x(t)\\
  x(t_0) =
  \left(
  \begin{array}{c}
    a_1 \\
    a_2 \\
    \cdots \\
    a_n
  \end{array}
  \right)
  \end{array}
  \right. ~~ \text{- решение задачи Коши}
  \varphi(t) =
  \left\{
  \begin{array}{c}
  x'(t) = A(t)x(t)\\
  x(t_0) =
  \left(
  \begin{array}{c}
    a_1 \\
    a_2 \\
    \cdots \\
    a_n
  \end{array}
  \right)
  \end{array}
  \right.
  $$
  $$
  \varphi(t_0) = a_1 \varphi_1(t_0) + \ldots + a_n \varphi_n(t_0) =
  a_1
  \left(
  \begin{array}{c}
    1 \\
    0 \\
    \cdots \\
    0
  \end{array}
  \right) +
  a_2
  \left(
  \begin{array}{c}
    0 \\
    1 \\
    \cdots \\
    0
  \end{array}
  \right) + \ldots +
  a_n
  \left(
  \begin{array}{c}
    0 \\
    0 \\
    \cdots \\
    1
  \end{array}
  \right) =
  \left(
  \begin{array}{c}
    a_1 \\
    a_2 \\
    \cdots \\
    a_n
  \end{array}
  \right)
  $$
  так как они обе удовлетворяеют задачи Коши то $\varphi(t) \equiv \psi(t) ~
  \Rightarrow ~ \psi(t) = \sum_{j=1}^n a_j \varphi_j(t)$
\end{proof}

\begin{define}[ФСР]
  ФСР - называется базис пространства решений тоесть $n$ - ЛНЗ решений данной
  системы
\end{define}

\begin{define}
  $\varphi_1(t), \ldots, \varphi_n(t)$ - вектор функции
  $$
  \varphi_j(t) =
  \left(
  \begin{array}{c}
    \varphi_{j1}(t) \\
    \varphi_{j1}(t) \\
    \cdots \\
    \varphi_{jn}(t)
  \end{array}
  \right)
  $$
  $$
  W[\varphi_1, \ldots, \varphi_n](t) =
  \left|
  \begin{array}{cccc}
    \varphi_{11}(t) & \varphi_{21}(t) & \ldots & \varphi_{n1}(t) \\
    \varphi_{12}(t) & \varphi_{22}(t) & \ldots & \varphi_{n2}(t) \\
    \ldots & \ldots & \ldots & \ldots \\
    \varphi_{1n}(t) & \varphi_{2n}(t) & \ldots & \varphi_{nn}(t)
  \end{array}
  \right|
  $$
\end{define}

\begin{block}[Утверждения]
  1) Если $\varphi_1(t), \ldots, \varphi_n(t)$ ЛЗ $\Rightarrow W(t) \equiv 0
  ~~~ t \in <\alpha, \beta>$

  2) Если $W(t) \not\equiv 0 ~ \Rightarrow ~ \varphi_1(t), \ldots,
  \varphi_n(t)$ ЛНЗ
\end{block}

\begin{block}[Критерий ЛНЗ решений системы]
  Пусть $\varphi_1, \ldots, \varphi_n(t)$
  решение задачи Коши тогда

  1) $W(t) = 0$ хотябы в одной точке
  $t \in <\alpha, \beta>$ то решение $\varphi_1(t), \ldots, \varphi_n(t)$ ЛЗ

  2) $\varphi_1, \ldots, \varphi_n(t)$ ЛНЗ то $W(t) \not0$ ни в одной точке
  $t \in <\alpha, \beta>$
\end{block}

\begin{proof}
  Пусть $W(t_0) = 0 ~~~ t \in <\alpha, \beta> ~ \Rightarrow ~ \varphi_1(t_1),
  \ldots, \varphi_n(t_1)$ ЛЗ $\exists C_1, \ldots, C_n ~~~
  C_1 \varphi_1(t_1) + \ldots + C_n \varphi_n (t_1) = 0$

  $\varphi(t) = C_1\varphi_1(t) + \ldots + C_n \varphi_n(t)$
  $$
  \varphi(t) =
  \left(
  \begin{array}{c}
    x'(t) = A(t)x(t) \\
    x(t_0) = 0
  \end{array}
  \right)
  $$
  $\psi \equiv 0$ другое решение $\Rightarrow ~ \varphi(t) = C_1 \varphi_1(t) +
  \ldots + C_n \varphi_n(t) \equiv 0 ~ \Rightarrow ~ \varphi_1, \ldots,
  \varphi_n$ ЛЗ \\
\end{proof}

\begin{theorem}
  $$
  W(t) =
  \left|
  \begin{array}{cccc}
    \varphi_{11}(t) & \varphi_{21}(t) & \ldots & \varphi_{n1}(t) \\
    \varphi_{12}(t) & \varphi_{22}(t) & \ldots & \varphi_{n2}(t) \\
    \ldots & \ldots & \ldots & \ldots \\
    \varphi_{1n}(t) & \varphi_{2n}(t) & \ldots & \varphi_{nn}(t)
  \end{array}
  \right|
  $$
  пусть $W(t)$ - определитель Вронского решение $\varphi_1(t), \ldots,
  \varphi_n(t)$ системы $x'(t) = A(t)x(t)$ то он является
  $\frac{W(t)}{dt} = (t_2A(t))W(t) ~~~ t \in <\alpha, \beta>$

  $t_2A(t) = a_{11}(t) + a_{22}(t) + \ldots + a_{nn}(t)$
\end{theorem}

\begin{block}[Формула Леовиля]
  $$
  W(t) = W(t_0)e^{\int_{t_0}^t t_2 A(s)ds}
  $$
  если определитель Вронского в некоторой точке $= 0$ то $W(t) \equiv 0$
\end{block}

\begin{title}[\Large]
  Фундаментальная матрица
\end{title}

\begin{define}
  Матрица $\Phi(t) ~ t \in <\alpha, \beta>$ называется решением системы
  $x'(t) = A(t)x(t)$ если столбцы матрицы являются решением системы
\end{define}

\begin{block}[Утверждение]
  $\Phi(t)$ является матрицей решений если удовлетворяет матричной системе
  $X'_{n \times n}(t) = A_{n \times n}(t) X_{n \times n}(t)$ $n$ - уравней
\end{block}

\begin{define}
  Невырожденная матрица решений называется фундаментальной матрицей
  $|\Phi(t)| = W(t)$ столбца ЛНЗ. Фкндаментальная матрица это матрица столбцы
  которой образуют ФСР
\end{define}

\begin{block}[Предложение]
  Если $\Phi(t)$ фундаментальная матрица $x'(t) = A(t)x(t)$
  тогда множество решений системы совпадает со множеством функций вида
  $\varphi(t) = \Phi(t)C$ где $C$ произвольный постоянный вектор из $e^n$
\end{block}

\begin{proof}
  $\Phi(t)$ фундаментальная матрица и $\varphi_1(t), \ldots, \varphi_n(t)$
  это ФСР

  $\Phi(t)C = (\varphi_1(t), \ldots, \varphi_n(t))C = C_1 \varphi_1(t) +
  C_2 \varphi_2(t) + \ldots + C_n \varphi_n(t)$
\end{proof}

\begin{block}[Утверждение]
  $\Phi(t)$ фундаментальная матрица $x'(t) = A(t)x(t)$ тогда множество всех
  фундаментальных матриц системы совпадает с множеством матриц следующего вида
  $\Psi(t) = \Phi(t)B ~~ detB \not= 0$
\end{block}

\begin{proof}
  так как $\Phi(t)$ фундаментальная матрица $det\Phi(t) \not= 0 ~~
  \forall t \in <\alpha, \beta>$ удовлетворяет $\Phi(t) = A(t)\Phi(t)$
  $det\Psi(t) \not= 0$ невырожденная

  $\Phi'(t)B = A(t)(\Phi(t)B)$

  $(\Phi(t)B)' = A(t)(\Phi(t)B)$

  $\Psi'(t) = A(t)\Psi(t)$ $\Psi$ - фундаментальная матрица \\

  Пусть $\Psi(t)$ фиксированная фундаментальная матрица

  $B = \Phi^{-1}(t_0) \Psi(t_0) ~~~ t_0 \in <\alpha, \beta>$

  $\Psi(t) = \Phi(t) \Phi_{-1}(t_0) \Psi(t_0)$

  $t = t_0 ~~~ \Phi(t_0) \Phi^{-1}(t_0) \Psi(t_0)$
  $$
  \left\{
  \begin{array}{c}
    X(t_0) = \Psi(t_0) \\
    X'(t) = A(t)X(t)
  \end{array}
  \right. ~ \Rightarrow ~
  \Psi(t) = \Phi(t) \Phi^{-1}(t_0)\Phi(t_0)
  $$
\end{proof}

Вывод: $x'(t) = A(t)x(t)$

1) Множество ее решений образует линейное пространство степени $n$

2) Для ее решения достаточно найти ФСР
$$
\varphi(t) = \sum_{j=1}^n C_j \varphi_j(t)
$$

\begin{title}[\Large]
  Линейная неоднородная системы
\end{title}

$x'(t) = A(t) x(t) + g(t) ~~~ t \in <\alpha, \beta>$ $A(t), g(t)$ -
непрерывные функции. Метод вариаций производных постоянных.

Расмотрим $x'(t) = A(t)x(t)$ $\Phi(t)$ - фундаментальная матрица
$x(t) = \Phi(t) C$ общее решение $x'(t) = A(t)x(t)$
$$
C =
\left\{
\begin{array}{c}
  C_1 \\
  C_2 \\
  \cdots \\
  C_n
\end{array}
\right) ~~~
C(t) =
\left\{
\begin{array}{c}
  C_1(t) \\
  C_2(t) \\
  \cdots \\
  C_n(t)
\end{array}
\right)
$$
$x(t) = \Phi(t)C(t) ~~~ x'(t) = \Phi'(t)C(t) + \Phi(t)C'(t)$

$\Phi'(t)C(t) + \Phi(t)C'(t) = A(t)\Phi(t)C(t) + g(t)$

$\Phi'(t) = A(t) \Phi(t)$

$\Phi(t)C'(t) = g(t)$

$C'(t) = \Phi^{-1}(t)g(t)$

$C(t) = \int_{t_0}^2 \Phi^{-1}(s)g(s)ds + D$

$x(t) = \Phi(t)D + \int_{t_0}^t\Phi(t) \Phi^{-1}(s)g(s)ds$ формула общего
решения. $x(t_0) = x_0$ задача Коши

$x(t_0) = \Phi(t_0)D ~~~ D = \Phi^{-1}(t_0)x(t_0)$

$x(t) = \Phi(t) \Phi^{-1}(t_0)x_0 + \int_{t_0}^t \Phi(t)\Phi^{-1}(s)g(s)ds$
формула Коши

$$
\left\{
\begin{array}{c}
  x'(t) = A(t)x(t) + g(t) \\
  x(t_0) = x_0
\end{array}
\right. ~~~ \text{задача Коши}
$$

\begin{theorem}
  Пусть $A(t), g(t)$ непрерывная матрица и вектор $t \in <\alpha, \beta>$ тогда
  решение задачи Коши определяется формулой Коши
\end{theorem}

$C(t,s) = \Phi(t)\Phi^{-1}(s)$ матрица Коши

$x(t) = C(t, t_0)x_0 + \int_{t_0}^t C(t,s)g(s)ds$

$C(t,s)$ зависит от выбора фундаментальной матрицы $\Phi(t)$. Пусть $\Psi(t)$
другая фундаментальная матрица $D(t,s) = \Psi(t)\Psi^{-1}(s)$ $\exists B$
невырожденаая матрица которая обеспечивает

$\Psi(t) = \Phi(t)B$

$\Psi^{-1}(s) = B^{-1} \Phi^{-1}(s)$

$\Psi(t) \Psi^{-1}(s) = \Phi(t) B B^{-1} \Phi^{-1}(s)$

$D(t, s) = C(t, s) ~ \Rightarrow$ функция Коши не зависит от выбра
фундаментальной матрица $\Phi(t)$

\begin{block}[Свойства]
  1) При каждом фиксиравоном $s \in <\alpha, \beta>$ $C(t, s)$ решение системы
  $X'(t) = A(t)X(t)$

  2) $C(t,t) = E$ еденичная матрица
\end{block}